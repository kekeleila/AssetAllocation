{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fix_yahoo_finance as yf  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def max_sharpe_port(stocks, start, end):\n",
    "    #download daily price data for each of the stocks in the portfolio\n",
    "    #data = web.DataReader(stocks,data_source='yahoo',start='01/01/2010')['Adj Close']\n",
    "    try:\n",
    "        data = yf.download(stocks,start,end)['Adj Close']\n",
    "    except:\n",
    "        return max_sharpe_port(stocks)\n",
    "    data.sort_index(inplace=True)\n",
    " \n",
    "    #convert daily stock prices into daily returns\n",
    "    returns = data.pct_change()\n",
    " \n",
    "    #calculate mean daily return and covariance of daily returns\n",
    "    mean_daily_returns = returns.mean()\n",
    "    cov_matrix = returns.cov()\n",
    " \n",
    "    #set number of runs of random portfolio weights\n",
    "    num_portfolios = 50000\n",
    " \n",
    "    #set up array to hold results\n",
    "    #We have increased the size of the array to hold the weight values for each stock\n",
    "    results = np.zeros((4+len(stocks)-1,num_portfolios))\n",
    " \n",
    "    for i in range(num_portfolios):\n",
    "        #select random weights for portfolio holdings\n",
    "        weights = np.array(np.random.random(len(stocks)))\n",
    "        #rebalance weights to sum to 1\n",
    "        weights /= np.sum(weights)\n",
    "    \n",
    "        #calculate portfolio return and volatility\n",
    "        portfolio_return = np.sum(mean_daily_returns * weights) * 252\n",
    "        portfolio_std_dev = np.sqrt(np.dot(weights.T,np.dot(cov_matrix, weights))) * np.sqrt(252)\n",
    "    \n",
    "        #store results in results array\n",
    "        results[0,i] = portfolio_return\n",
    "        results[1,i] = portfolio_std_dev\n",
    "        #store Sharpe Ratio (return / volatility) - risk free rate element excluded for simplicity\n",
    "        results[2,i] = results[0,i] / results[1,i]\n",
    "        #iterate through the weight vector and add data to results array\n",
    "        for j in range(len(weights)):\n",
    "            results[j+3,i] = weights[j]\n",
    "     \n",
    "    #convert results array to Pandas DataFrame\n",
    "    columns = ['ret', 'stdev', 'sharpe'] + stocks\n",
    "    results_frame = pd.DataFrame(results.T,columns= columns)\n",
    " \n",
    "    #locate position of portfolio with highest Sharpe Ratio\n",
    "    max_sharpe_port = results_frame.iloc[results_frame['sharpe'].idxmax()]\n",
    "    #locate positon of portfolio with minimum standard deviation\n",
    "    min_vol_port = results_frame.iloc[results_frame['stdev'].idxmin()]\n",
    " \n",
    "    #create scatter plot coloured by Sharpe Ratio\n",
    "    #plt.scatter(results_frame.stdev,results_frame.ret,c=results_frame.sharpe,cmap='RdYlBu')\n",
    "    #plt.xlabel('Volatility')\n",
    "    #plt.ylabel('Returns')\n",
    "    #plt.colorbar()\n",
    "    #plot red star to highlight position of portfolio with highest Sharpe Ratio\n",
    "    #plt.scatter(max_sharpe_port[1],max_sharpe_port[0],marker=(5,1,0),color='r',s=1000)\n",
    "    #plot green star to highlight position of minimum variance portfolio\n",
    "    #plt.scatter(min_vol_port[1],min_vol_port[0],marker=(5,1,0),color='g',s=1000)\n",
    "    #plt.show()\n",
    "    return max_sharpe_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stocks = ['ALL',\n",
    " 'MMC',\n",
    " 'PGR',\n",
    " 'MA',\n",
    " 'AIG',\n",
    " 'AON',\n",
    " 'CME',\n",
    " 'CFG',\n",
    " 'RF',\n",
    " 'PYPL',\n",
    " 'ADBE',\n",
    " 'NVDA',\n",
    " 'FB',\n",
    " 'CTXS',\n",
    " 'XLNX',\n",
    " 'NTAP',\n",
    " 'ADSK',\n",
    " 'LRCX',\n",
    " 'AYI',\n",
    " 'AMD',\n",
    " 'WEC',\n",
    " 'SCG',\n",
    " 'CMS',\n",
    " 'XEL',\n",
    " 'NEE',\n",
    " 'EXC',\n",
    " 'PPL',\n",
    " 'PCG',\n",
    " 'NRG',\n",
    " 'CPN',\n",
    " 'VLO',\n",
    " 'EQT',\n",
    " 'WMB',\n",
    " 'KMI',\n",
    " 'CVX',\n",
    " 'RIG',\n",
    " 'NFX',\n",
    " 'SLB',\n",
    " 'ESV',\n",
    " 'SWN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Brenchmark = ['^GSPC']\n",
    "\n",
    "ETF = ['SPY', 'EEM', 'OIL', 'FXI', 'JNK', 'VCSH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  40 of 40 downloaded\n"
     ]
    }
   ],
   "source": [
    "max_sharpe_port_stock_pre = max_sharpe_port(stocks,'2017-02-15','2018-02-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  40 of 40 downloaded\n"
     ]
    }
   ],
   "source": [
    "max_sharpe_port_stock_cur = max_sharpe_port(stocks,'2017-02-26','2018-02-26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  6 of 6 downloaded\n"
     ]
    }
   ],
   "source": [
    "max_sharpe_port_etf_pre = max_sharpe_port(ETF,'2017-02-15','2018-02-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  6 of 6 downloaded\n"
     ]
    }
   ],
   "source": [
    "max_sharpe_port_etf_cur = max_sharpe_port(ETF,'2017-02-26','2018-02-26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "previous_stocks = max_sharpe_port_stock_pre.as_matrix()\n",
    "current_stocks = max_sharpe_port_stock_cur.as_matrix()\n",
    "previous_etf = max_sharpe_port_etf_pre.as_matrix()\n",
    "current_etf = max_sharpe_port_etf_cur.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_weight_change = current_stocks - previous_stocks\n",
    "etf_weight_change = current_etf - previous_etf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  40 of 40 downloaded\n"
     ]
    }
   ],
   "source": [
    "stock_data_cur = yf.download(stocks,'2018-02-26','2018-02-26')['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  6 of 6 downloaded\n"
     ]
    }
   ],
   "source": [
    "etf_data_cur = yf.download(ETF,'2018-02-26','2018-02-26')['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ADBE      ADSK       AIG       ALL       AMD       AON  \\\n",
      "Date                                                                     \n",
      "2018-02-26 -0.506911 -0.460658  1.315299 -2.305175 -0.143159 -0.755998   \n",
      "\n",
      "                 AYI       CFG       CME       CMS    ...          RF  \\\n",
      "Date                                                  ...               \n",
      "2018-02-26 -4.552453  0.730607  1.140649 -0.802072    ...    -0.38565   \n",
      "\n",
      "                 RIG       SCG       SLB       SWN       VLO       WEC  \\\n",
      "Date                                                                     \n",
      "2018-02-26  0.197305 -0.100541  0.574735  0.026037 -1.431488  1.614943   \n",
      "\n",
      "                 WMB       XEL      XLNX  \n",
      "Date                                      \n",
      "2018-02-26 -0.381421  0.140909 -0.801497  \n",
      "\n",
      "[1 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "#change in dollar amount for each stock\n",
    "print(np.multiply(stock_data_cur,stock_weight_change[3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 EEM       FXI       JNK       OIL       SPY       VCSH\n",
      "Date                                                                   \n",
      "2018-02-26 -11.43448  0.407702 -0.881404  0.061346 -0.825171  18.728377\n"
     ]
    }
   ],
   "source": [
    "print(np.multiply(etf_data_cur,etf_weight_change[3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_return(stocks,start,end,max_sharpe_port):\n",
    "    try:\n",
    "        dataPrevious = yf.download(stocks,start,start)['Adj Close']\n",
    "        dataCurrent = yf.download(stocks,end,end)['Adj Close']\n",
    "    except:\n",
    "        return compute_return(stocks,start,end,max_sharpe_port)\n",
    "    previous = dataPrevious.as_matrix()\n",
    "    Current = dataCurrent.as_matrix()\n",
    "    \n",
    "    current_return = (Current - previous)/Current\n",
    "    weights = max_sharpe_port[3:]\n",
    "    weighted_return = np.dot((Current - previous)/Current,weights)\n",
    "    \n",
    "    return weighted_return\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def betaCalculate(stocks):\n",
    "    result = []\n",
    "    for i in stocks:\n",
    "        try:\n",
    "            ret = yf.download(i,'2017-02-26','2018-02-26')['Adj Close'].pct_change()[1:].values\n",
    "        except:\n",
    "            print('error') #betaCalculate(stocks)\n",
    "        result.append(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n"
     ]
    }
   ],
   "source": [
    "stockBeta = betaCalculate(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[[...]]\n"
     ]
    }
   ],
   "source": [
    "benchmarkBeta = betaCalculate(['^GSPC'])\n",
    "print(benchmarkBeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n"
     ]
    }
   ],
   "source": [
    "etfBeta = betaCalculate(ETF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lantinghe/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linreg(ret_stocks, ret_benchMark):\n",
    "    ret_stocks = sm.add_constant(ret_stocks)\n",
    "    model = regression.linear_model.OLS(ret_benchMark, ret_stocks).fit()\n",
    "    ret_stocks = ret_stocks[:,1]\n",
    "    return model.params[0], model.params[1]\n",
    "alpha,beta = linreg(etfBeta, benchmarkBeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
